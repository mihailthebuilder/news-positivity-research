{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# News Positivity Research\n",
    "\n",
    "This is the Jupyter notebook that shows how to scrape all the text content from a single news site. The sentiment scoring is done in the [model.ipynb](./model.ipynb) notebook. \n",
    "\n",
    "The script is designed to work only for the landing pages (e.g. https://bbc.co.uk), not for the article pages (e.g. https://www.bbc.co.uk/news/uk-england-birmingham-58282348)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My analysis was done on 3 URLs:\n",
    "- positive.news\n",
    "- bbc.co.uk\n",
    "- thecanary.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"positive.news\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the HTML text from the website. The news sites get constantly updated, which is why I needed to download the content into text files. Run as-is if you wish to replicate my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def request(url):\n",
    "    \"\"\"sends a request to the URL\"\"\"\n",
    "\n",
    "    # add https if not in there at start\n",
    "    if url[0:8] != \"https://\" and url[0:7] != \"http://\":\n",
    "        url = \"https://\" + url\n",
    "\n",
    "    my_session = requests.session()\n",
    "    \n",
    "    # these settings help avoid getting blocked by site\n",
    "    for_cookies = requests.get(url, timeout=5).cookies\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:57.0) Gecko/20100101 Firefox/57.0\"\n",
    "    }\n",
    "\n",
    "    return my_session.get(url, headers=headers, cookies=for_cookies, timeout=5)\n",
    "\n",
    "#response = request(url)\n",
    "\n",
    "#with open(url+\"-html_text.txt\", \"w\") as text_file:\n",
    "#    text_file.write(response.text)\n",
    "\n",
    "with open(url+\"-html_text.txt\",\"r\") as text_file:\n",
    "    response_text = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<!--[if lt IE 7]><html class=\"no-js ie ie6 lt-ie9 lt-ie8 lt-ie7\" lang=\"en\"> <![endif]-->\\n<!--[if IE 7]><html class=\"no-js ie ie7 lt-ie9 lt-ie8\" lang=\"en\"> <![endif]-->\\n<!--[if IE 8]><h'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pull out all the relevant text content from the HTML of the websites. We'll start by splitting the HTML text into an array of text pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "soup_li = bs(response_text, \"lxml\").body.get_text(separator=\"||\").split(\"||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_li[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of generic text. We can remove the far majority with 2 filters:\n",
    "1) Must have at least 5 words\n",
    "2) Must not include generic site keywords like `sign up` or `newsletter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = [\"cookie\",\n",
    "            \"newsletter\",\n",
    "            \"copyright\",\n",
    "            \"trademark\",\n",
    "            \"mailing list\",\n",
    "            \"subscribe\",\n",
    "            \"sign up\",\n",
    "            \"rights reserved\",\n",
    "            \"this site\",\n",
    "            \"©\",\n",
    "            \"ltd\",\n",
    "            \"llp\",\n",
    "            \"inc\"\n",
    "           ]\n",
    "\n",
    "def is_generic(text):\n",
    "    if len(text.split()) < 5:\n",
    "        return True\n",
    "    \n",
    "    lower_text = text.lower()\n",
    "    \n",
    "    for word in KEYWORDS:\n",
    "        if word in lower_text:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "long_text = [x for x in soup_li if not is_generic(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What can I do about climate change? 14 ways to take positive action',\n",
       " 'After the UN issued a ‘code red for humanity’ last week, many people are asking — what can I do about climate change? Quite a lot, actually ',\n",
       " 'The cookbook for people who have long Covid',\n",
       " '\\n          The authors of a new, free cookbook hope it will improve taste for Covid patients\\n        ',\n",
       " 'Wind power firm aims to nip nimbyism in the bud with tulip-shaped turbines',\n",
       " \"\\n          Want to improve your business's eco-credentials, and ward off nimby naysayers? Flower Turbines may be the ticket \\n        \",\n",
       " 'Meet the plastic-hunting ‘pirates’ of Cornwall',\n",
       " '\\n          The pirates’ bounty is melted down to make sea kayaks, which are then used to collect more rubbish   \\n        ',\n",
       " 'What went right this week: Australia’s ‘healing journey’, plus more positive news',\n",
       " '\\n          Australia pledged reparations for indigenous people, wildlife returned to Scottish rivers, plus coffee shops that help homeless people\\n        ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there's some duplicates. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_li = []\n",
    "\n",
    "for text_l in long_text:\n",
    "    unique = True\n",
    "    \n",
    "    for text_u in unique_li:\n",
    "        if text_l in text_u:\n",
    "            unique = False\n",
    "        \n",
    "    if unique:\n",
    "        unique_li.append(text_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What can I do about climate change? 14 ways to take positive action',\n",
       " 'After the UN issued a ‘code red for humanity’ last week, many people are asking — what can I do about climate change? Quite a lot, actually ',\n",
       " 'The cookbook for people who have long Covid',\n",
       " '\\n          The authors of a new, free cookbook hope it will improve taste for Covid patients\\n        ',\n",
       " 'Wind power firm aims to nip nimbyism in the bud with tulip-shaped turbines',\n",
       " \"\\n          Want to improve your business's eco-credentials, and ward off nimby naysayers? Flower Turbines may be the ticket \\n        \",\n",
       " 'Meet the plastic-hunting ‘pirates’ of Cornwall',\n",
       " '\\n          The pirates’ bounty is melted down to make sea kayaks, which are then used to collect more rubbish   \\n        ',\n",
       " 'What went right this week: Australia’s ‘healing journey’, plus more positive news',\n",
       " '\\n          Australia pledged reparations for indigenous people, wildlife returned to Scottish rivers, plus coffee shops that help homeless people\\n        ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_li[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some empty spaces and weird characters due to HTML encoding. Let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_transform(text_input):\n",
    "    encoded_text = text_input.encode(\"ascii\", \"ignore\")\n",
    "    decoded_text = encoded_text.decode(\"unicode_escape\")\n",
    "    stripped_text = re.sub(\n",
    "        r\"\\r|\\n|\\t| \\(link opens in a new browser window\\)\", \"\", decoded_text\n",
    "    ).strip()\n",
    "    return stripped_text\n",
    "\n",
    "processed_li = [text_transform(x) for x in unique_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What can I do about climate change? 14 ways to take positive action',\n",
       " 'After the UN issued a code red for humanity last week, many people are asking  what can I do about climate change? Quite a lot, actually',\n",
       " 'The cookbook for people who have long Covid',\n",
       " 'The authors of a new, free cookbook hope it will improve taste for Covid patients',\n",
       " 'Wind power firm aims to nip nimbyism in the bud with tulip-shaped turbines',\n",
       " \"Want to improve your business's eco-credentials, and ward off nimby naysayers? Flower Turbines may be the ticket\",\n",
       " 'Meet the plastic-hunting pirates of Cornwall',\n",
       " 'The pirates bounty is melted down to make sea kayaks, which are then used to collect more rubbish',\n",
       " 'What went right this week: Australias healing journey, plus more positive news',\n",
       " 'Australia pledged reparations for indigenous people, wildlife returned to Scottish rivers, plus coffee shops that help homeless people']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_li[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "token_df = pd.DataFrame(processed_li,columns=[\"text\"])\n",
    "token_df[\"site\"] = url\n",
    "\n",
    "## Commented out to avoid overwriting\n",
    "#token_df.to_csv(url+\"-csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I ran this for the 3 news sites, I manually combined all of them into the `test.csv` file."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34e04979d73b2ceef69adabefb5e026b4557b5b2bae59a0151ac0f9ce1842be6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
