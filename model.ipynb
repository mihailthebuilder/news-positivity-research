{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d6a802-001e-4779-89fd-1844f7e2321d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# News Positivity Research\n",
    "\n",
    "## Intro\n",
    "\n",
    "This notebook assesses the performance of several pre-trained models for scoring the positivity of news sites:\n",
    "- [AFINN](https://github.com/fnielsen/afinn)\n",
    "- [VADER](https://github.com/cjhutto/vaderSentiment)\n",
    "- [DistilBERT](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "- [roBERTa](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)\n",
    "- [BERTweet](https://huggingface.co/cardiffnlp/bertweet-base-sentiment)\n",
    "\n",
    "AFINN and VADER are two popular dictionary-based models. DistilBERT is the default sentiment analysis model offered by Hugging Face in their [quick tour](https://huggingface.co/transformers/quicktour.html). roBERTa and BERTweet are two of the best performing models in the [TweetEval benchmark study](https://arxiv.org/pdf/2010.12421.pdf).\n",
    "\n",
    "We're only looking at the landing pages (e.g. https://bbc.co.uk) and not the article pages (e.g. https://www.bbc.co.uk/news/uk-england-birmingham-58282348).\n",
    "\n",
    "The [test.csv](./test.csv) file contains the test dataset. The text content in the dataset was gathered using the [data.ipynb](./data.ipynb) script, which was run on 3 websites: [bbc.co.uk](https:/bbc.co.uk), [thecanary.co](https://thecanary.co) and [positive.news](https://positive.news). For each text piece, I manually assigned a sentiment score of -1 if it was negative, and +1 if it was neutral or positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5efd6-dd39-4342-b6c6-dc60563cb0b8",
   "metadata": {},
   "source": [
    "We start by loading the test dataset into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9eadb5d-4286-4be1-b3ad-e13b9822905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef44bb-69e7-4e3b-83b7-0bc5b9214632",
   "metadata": {},
   "source": [
    "Score the dataset with AFINN and VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3deb9184-f41e-4d6a-a192-c2f5edde8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "afinn = Afinn()\n",
    "results[\"afinn\"] = results.apply(lambda row: 1 if afinn.score(row[\"text\"]) >= 0 else -1, axis=1)\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "results[\"vader\"] = results.apply(lambda row: 1 if vader.polarity_scores(row[\"text\"])[\"compound\"] >= 0 else -1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad2e16-5814-449d-afe1-af82ac60e6f8",
   "metadata": {},
   "source": [
    "Score the dataset with DistilBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0a6385-deb0-46ed-b4ef-ec601b329508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "results[\"distilbert\"] = results.apply(lambda row: -1 if classifier(row[\"text\"])[0][\"label\"] == \"NEGATIVE\" else 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29523c38-d1ac-4305-8d69-77fd418bbe81",
   "metadata": {},
   "source": [
    "Fetch the roBERTa model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2212794c-11e2-45e7-99f9-105819fa29f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "ROBERTA_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(ROBERTA_MODEL)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(ROBERTA_MODEL)\n",
    "\n",
    "## Un-comment when first run so you can download the model on your local machine.\n",
    "#roberta_model.save_pretrained(ROBERTA_MODEL)\n",
    "#roberta_tokenizer.save_pretrained(ROBERTA_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf8ee8-2458-4607-be78-2d8e0c69359d",
   "metadata": {},
   "source": [
    "Score the dataset with roBERTa. We've defined the `model_output` function as we'll use it when scoring with BERTweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dfb7e74-e218-4cd5-9569-35224577be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "def model_output(text_input, model_input, tokenizer_input):\n",
    "    encoded_input = tokenizer_input(text_input, return_tensors='pt')\n",
    "    output = model_input(**encoded_input)\n",
    "    \n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    if scores[0] > scores[1] and scores[0] > scores[2]:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "results[\"roberta\"] = results.apply(lambda row: model_output(row[\"text\"], roberta_model, roberta_tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328028c6-901d-4b47-b9f3-aecfd3cc6124",
   "metadata": {},
   "source": [
    "Fetch the BERTweet model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff0c8fa6-8b76-4714-83d7-60d3efbccf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Please install emoji: pip3 install emoji\n"
     ]
    }
   ],
   "source": [
    "BERTWEET_MODEL = \"cardiffnlp/bertweet-base-sentiment\"\n",
    "bertweet_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL)\n",
    "bertweet_model = AutoModelForSequenceClassification.from_pretrained(BERTWEET_MODEL)\n",
    "\n",
    "## Un-comment when first run so you can download the model on your local machine.\n",
    "#bertweet_model.save_pretrained(BERTWEET_MODEL)\n",
    "#bertweet_tokenizer.save_pretrained(BERTWEET_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac7bf9-6fef-4dc1-a5de-2ef950eca046",
   "metadata": {},
   "source": [
    "Score the dataset with BERTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23772743-28f3-43de-9f83-d8d93d637960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results[\"bertweet\"] = results.apply(lambda row: model_output(row[\"text\"], bertweet_model, bertweet_tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21e903-796e-4212-b085-0e995f2401b4",
   "metadata": {},
   "source": [
    "Assess the accuracy of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b06858e-33a6-4478-ab78-eb69f49d4fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afinn 75.2%\n",
      "vader 71.8%\n",
      "distilbert 65.8%\n",
      "roberta 79.5%\n",
      "bertweet 77.8%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for model in [\"afinn\",\"vader\",\"distilbert\",\"roberta\",\"bertweet\"]:\n",
    "    print(model, str(round(accuracy_score(results[\"sentiment\"],results[model])*100,1))+\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
